{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrederikskoufertin\u001b[0m (\u001b[33mPyepo_special\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import pyepo\n",
    "from pyepo.model.grb import optGrbModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import wandb \n",
    "wandb.login()\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pyepo.metric.regretParams import regretParams\n",
    "# train model\n",
    "\n",
    "#from sklearn_extra.cluster import KMedoids\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "red = (0.77, 0, 0.05) # (196, 0, 13)\n",
    "blue = (0.12, 0.24, 1) # (31, 61, 255)\n",
    "# green = (0.31, 1, 0.34) # (79, 255, 87)\n",
    "green = (0.122, 00.816, 0.51) # (31, 208, 130)\n",
    "navyblue = (0, 0, 0.4) # (0, 0, 102)\n",
    "black = (0, 0, 0)\n",
    "white = (1, 1, 1)\n",
    "cgreen = (0.57254902, 0.7254902 , 0.51372549) # (146, 185, 131)\n",
    "cblue = (0.70196078, 0.83137255, 1) # (179, 212, 255)\n",
    "\n",
    "top_domain = 53.32 # 90% quantile\n",
    "\n",
    "\n",
    "\n",
    "def import_data(negative_prices=False):\n",
    "    # import data and set constants\n",
    "    all_data = pd.read_csv(\"2020_data.csv\")\n",
    "    prices_UP = np.maximum(all_data[\"UP\"].to_numpy(),0)\n",
    "    prices_DW = np.maximum(all_data[\"DW\"].to_numpy(),0)\n",
    "    prices_F = np.maximum(all_data[\"forward_RE\"].to_numpy(),0)\n",
    "    prices_forecast = np.maximum(all_data[\"forward_FC\"].to_numpy(), 0)\n",
    "\n",
    "    nominal_wind = 10\n",
    "    features = all_data.loc[:, [\"Offshore DK2\", \"Offshore DK1\", \"Onshore DK2\", \"Onshore DK1\", \"production_FC\"]]\n",
    "    features[\"forward\"] = prices_F\n",
    "    features_red = all_data.loc[:, [\"production_FC\"]]\n",
    "    features_red[\"forward\"] = prices_F\n",
    "    realized = all_data.loc[:, \"production_RE\"].to_numpy()\n",
    "    realized *= nominal_wind\n",
    "\n",
    "    price_H = 35.2\n",
    "    penalty = np.quantile(prices_UP, 0.95) # 95% quantile of deficit_settle price over all 2 years\n",
    "    # penalty = 2 * price_H\n",
    "    # penalty = np.max(prices_B) # Something HIGHER is needed apparently\n",
    "\n",
    "    return (\n",
    "        prices_UP,\n",
    "        prices_DW,\n",
    "        prices_F,\n",
    "        prices_forecast,\n",
    "        features,\n",
    "        features_red,\n",
    "        realized,\n",
    "        price_H,\n",
    "        penalty\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "(prices_UP,prices_DW,prices_F,prices_forecast,features,features_red,realized,price_H,penalty) = import_data()\n",
    "\n",
    "# Change forward prices to forecast prices in features\n",
    "features[\"forward\"] = prices_forecast\n",
    "\n",
    "periods = list(range(0, len(prices_F) )) # Total time considered 2020-2021\n",
    "n_periods = 24 # Number of periods in a day\n",
    "n_days = 50 # Number of days in training set and test set\n",
    "n_hours = n_days * n_periods\n",
    "# 4 without extra hydrogen 5 with extra hydrogen\n",
    "num_cost = 5 # number of cost parameters\n",
    "num_feat = n_periods*6 # size of feature\n",
    "num_feat_rf = 2 # size of feature\n",
    "num_item = num_cost*n_periods # number of predictions (Forward bid and Hydrogen)\n",
    "num_feat = n_periods*6 # size of feature\n",
    "#n_val_days = 10 # number of validation days \n",
    "#n_hours_val = n_periods*n_val_days\n",
    "lambda_H_list = [price_H for i in range(n_periods)]\n",
    "penalty_list = [-penalty for i in range(n_periods)]\n",
    "\n",
    "lambda_H_list = [price_H for i in range(n_periods)]\n",
    "penalty_list = [-penalty for i in range(n_periods)]\n",
    "\n",
    "def flatten_extend(matrix):\n",
    "     flat_list = []\n",
    "     for row in matrix:\n",
    "         flat_list.extend(row)\n",
    "     return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyepo.model.grb import optGrbModel\n",
    "num_item = 5*n_periods # number of predictions (Forward bid and Hydrogen)\n",
    "\n",
    "# optimization model\n",
    "class hydrogenPlanning_2(optGrbModel):\n",
    "    def __init__(self, realized, *args, **kwargs):        \n",
    "        #Fixed parameters\n",
    "        self.max_elec = 10\n",
    "        self.max_wind = 10\n",
    "        self.nominal_wind = 10\n",
    "        self.min_production = 50\n",
    "        self.periods = np.arange(len(realized))\n",
    "        self.E_real = realized\n",
    "        super().__init__()\n",
    "\n",
    "    def _getModel(self):\n",
    "\n",
    "        self.initial_plan = Model(\"Gurobi.Optimizer\")\n",
    "\n",
    "        # Definition of variables\n",
    "        self.var = self.initial_plan.addVars((5*len(self.periods)), name=\"x\")\n",
    "        # 1-24: Hydrogen plan, 25-48: Forward bids, 49-72: Up regulation, 73-96: Down regulation\n",
    "        #97-120: Hydrogen extra\n",
    "        # Objective: Maximize profit\n",
    "        self.initial_plan.modelSense = GRB.MAXIMIZE\n",
    "\n",
    "        # Constraints\n",
    "        # Max capacity\n",
    "        self.initial_plan.addConstr(self.min_production <= gp.quicksum(self.var[t] for t in self.periods), name=\"min_hydrogen_production\")\n",
    "        for t in np.arange(0,len(self.periods)):\n",
    "            self.initial_plan.addConstr(self.var[t] >= 0, name=f\"elec_capacity_lb_{t}\")\n",
    "            self.initial_plan.addConstr(self.var[t] <= self.max_elec, name=f\"elec_capacity_ub_{t}\")\n",
    "        for t in np.arange(len(self.periods),2*len(self.periods)):\n",
    "            self.initial_plan.addConstr(self.var[t] >= -self.max_elec, name=f\"wind_capacity_lb_{t}\")\n",
    "            self.initial_plan.addConstr(self.var[t] <= self.max_wind, name=f\"wind_capacity_ub_{t}\")\n",
    "        for t in np.arange(2*len(self.periods),3*len(self.periods)):\n",
    "            self.initial_plan.addConstr(self.var[t] >= 0, name=f\"up_regulation_lb_{t}\")\n",
    "            self.initial_plan.addConstr(self.var[t] <= 10*self.max_wind, name=f\"up_regulation_ub_{t}\")\n",
    "        for t in np.arange(3*len(self.periods),4*len(self.periods)):\n",
    "            self.initial_plan.addConstr(self.var[t] >= 0, name=f\"dw_regulation_lb_{t}\")\n",
    "            self.initial_plan.addConstr(self.var[t] <= 10*self.max_wind, name=f\"dw_regulation_ub_{t}\")\n",
    "\n",
    "        #notsure about this one\n",
    "        for t in np.arange(0,len(self.periods)):\n",
    "            self.initial_plan.addConstr(self.var[t] + self.var[t+24] <= self.max_wind, name=f\"{t}\")\n",
    "        #added constraints for extra hydrogen\n",
    "        for t in np.arange(4*len(self.periods),5*len(self.periods)):\n",
    "            self.initial_plan.addConstr(self.var[t] >= -self.max_elec, name=f\"extra_hydrogen_lb_{t}\")\n",
    "            self.initial_plan.addConstr(self.var[t] <= self.max_elec, name=f\"extra_hydrogen_ub_{t}\")\n",
    "       #Balance constraint \n",
    "        for t in np.arange(0,len(self.periods)):\n",
    "            self.initial_plan.addConstr(self.E_real[t] - self.var[t] - self.var[t+24] == -self.var[t+48] + self.var[t+72] + self.var[t+96], name=f\"balancing_{t}\")\n",
    "            #initial_plan.addConstr(-x[0,t] + self.min_production/len(self.periods) - x[4,t] <= 0, name=f\"slack_{t}\")\n",
    "\n",
    "\n",
    "        # Reference point is from extra hydrogen, so initial has to be tt-24*4\n",
    "        for ix, t in enumerate(np.arange(4*len(self.periods),5*len(self.periods))):\n",
    "            if ix == 0:\n",
    "                # Must not reduce below min production\n",
    "                self.initial_plan.addConstr(self.var[t] >= \n",
    "                                            - (gp.quicksum(self.var[tt] for tt in np.arange(ix,len(self.periods))) - self.min_production), \"c1\")\n",
    "            else:\n",
    "                # Must not reduce below min production - can do if we have produced more than min production earlier\n",
    "                self.initial_plan.addConstr(self.var[t] >= \n",
    "                                            - (gp.quicksum(self.var[tt-24*4] \n",
    "                                                           + self.var[tt] for tt in np.arange(4*len(self.periods),t-1)) +\n",
    "                                          gp.quicksum(self.var[tt-24*4] for tt in np.arange(t,5*len(self.periods))) \n",
    "                                          - self.min_production), \"c2\")\n",
    "            # Cannot produce more than max capacity:\n",
    "            self.initial_plan.addConstr(self.var[t] + self.var[t-24*4] <= self.max_elec, \"Extra hydrogen production capacity\")\n",
    "            self.initial_plan.addConstr(self.var[t] + self.var[t-24*4] >= 0, \"Extra hydrogen production capacity\")        \n",
    "            \"\"\"\"\n",
    "            how to implement this? without cost or objective function?\n",
    "            if lambda_H < price_DW[t,s]\n",
    "                @constraint(SAA, EH_extra[t,s] <= 0)\n",
    "            end\n",
    "            \"\"\"\n",
    "        \n",
    "        return self.initial_plan, self.var\n",
    "    \n",
    "    def setObjective(self, c):\n",
    "        # Objective: Maximize profit\n",
    "        self.initial_plan.setObjective(gp.quicksum(self.var[t]*c[t] for t in np.arange(0,5*len(self.periods))), GRB.MAXIMIZE)\n",
    "        for t in np.arange(4*len(self.periods),5*len(self.periods)):\n",
    "            if c[t] < c[t-24]: # if lambda_H[t] < price_DW[t]\n",
    "                    self.initial_plan.addConstr(self.var[t] <= 0)\n",
    "\n",
    "    def get_plan(self):\n",
    "        self.initial_plan.optimize()\n",
    "        self.initial_plan.update()\n",
    "        x_values = []\n",
    "        for var in self.initial_plan.getVars():\n",
    "            x_values.append(var.x)\n",
    "        hydrogen = x_values[0:len(self.periods)]\n",
    "        forward_bids = x_values[len(self.periods):2*len(self.periods)]\n",
    "        return forward_bids, hydrogen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visLearningCurve(loss_log, loss_log_regret):\n",
    "    # create figure and subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,4))\n",
    "\n",
    "    # draw plot for training loss\n",
    "    ax1.plot(loss_log, color=\"c\", lw=1)\n",
    "    ax1.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax1.set_xlabel(\"Iters\", fontsize=16)\n",
    "    ax1.set_ylabel(\"Loss\", fontsize=16)\n",
    "    ax1.set_title(\"Learning Curve on Training Set\", fontsize=16)\n",
    "\n",
    "    # draw plot for regret on test\n",
    "    ax2.plot(loss_log_regret, color=\"royalblue\", ls=\"--\", alpha=0.7, lw=1)\n",
    "    ax2.set_xticks(range(0, len(loss_log_regret), 2))\n",
    "    ax2.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.set_xlabel(\"Epochs\", fontsize=16)\n",
    "    ax2.set_ylabel(\"Regret\", fontsize=16)\n",
    "    ax2.set_title(\"Learning Curve on Test Set\", fontsize=16)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wind_train = np.asarray([flatten_extend([realized[d:d+n_periods]]) for d in range(int(n_hours/n_periods))])\n",
    "#wind_val   = wind_train[-n_val_days:,:]\n",
    "#wind_train   = wind_train[:(n_days-n_val_days),:]\n",
    "wind_test = np.asarray([flatten_extend([realized[d:d+n_periods]]) for d in range(int(n_hours/n_periods), int(2*n_hours/n_periods))])\n",
    "\"\"\"\n",
    "x_train = np.asarray([flatten_extend(features.values[d:d+n_periods]) for d in range(int(n_hours/n_periods))])\n",
    "x_test = np.asarray([flatten_extend(features.values[d:d+n_periods]) for d in range(int(n_hours/n_periods), int(2*n_hours/n_periods))])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "x_train_df = features.iloc[:n_hours]\n",
    "\n",
    "#x_train_df = features.iloc[:(n_hours-n_hours_val)]\n",
    "#x_val_df = features.iloc[(n_hours-n_hours_val):n_hours]\n",
    "x_test_df = features.iloc[n_hours:(n_hours+n_hours)]\n",
    "\n",
    "\n",
    "# Create a StandardScaler object (fitted on train data)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_df)\n",
    "\n",
    "# Standardize train and test dataframes separately\n",
    "x_train_df = pd.DataFrame(scaler.transform(x_train_df), columns=x_train_df.columns)\n",
    "#x_val_df = pd.DataFrame(scaler.transform(x_val_df), columns=x_val_df.columns)\n",
    "x_test_df = pd.DataFrame(scaler.transform(x_test_df), columns=x_test_df.columns)\n",
    "\n",
    "\n",
    "x_train = []\n",
    "#x_val = []\n",
    "#for i in range(0, len(x_val_df), 24):\n",
    "#    x_val.append((x_val_df.iloc[i:i+24]).values.T.flatten())\n",
    "x_test = []\n",
    "for i in range(0, len(x_train_df), 24):\n",
    "    x_train.append((x_train_df.iloc[i:i+24]).values.T.flatten())  # Extract 24 rows for each day\n",
    "\n",
    "for i in range(0, len(x_test_df), 24):\n",
    "    x_test.append((x_test_df.iloc[i:i+24]).values.T.flatten()) \n",
    "\n",
    "\n",
    "# Standardize x_train and x_test\n",
    "#train_mean = np.mean(x_train, axis=0)\n",
    "#train_std = np.std(x_train, axis=0)\n",
    "#x_train_stand = (x_train - train_mean) / train_std\n",
    "#x_test_stand = (x_test - train_mean) / train_std\n",
    "\n",
    "c_train = np.asarray([flatten_extend([lambda_H_list, prices_F[d: d+n_periods], -prices_UP[d: d+n_periods], prices_DW[d: d+n_periods],lambda_H_list]) for d in range(int(n_hours/n_periods))])\n",
    "#c_val   = c_train[-n_val_days:,:]\n",
    "#c_train   = c_train[:(n_days-n_val_days),:]\n",
    "c_test = np.asarray([flatten_extend([lambda_H_list, prices_F[d: d+n_periods], -prices_UP[d: d+n_periods], prices_DW[d: d+n_periods],lambda_H_list]) for d in range(int(n_hours/n_periods), int(2*n_hours/n_periods))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 81.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 71.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyepo.data.datasetParams import optDatasetParams\n",
    "dataset_train = optDatasetParams(hydrogenPlanning_2, x_train, c_train, wind_train)\n",
    "#dataset_val = optDatasetParams(hydrogenPlanning, x_val, c_val, wind_val)\n",
    "dataset_test = optDatasetParams(hydrogenPlanning_2, x_test, c_test, wind_test)\n",
    "\n",
    "batch_size = 1\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "#loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction model\n",
    "from torch import nn\n",
    "\n",
    "# Initialize the model\n",
    "constant_indices = np.zeros(num_item)\n",
    "constant_indices[0:24] = 1\n",
    "constant_indices[num_item-24:num_item] = 1\n",
    "grad_mask = (constant_indices == 0).astype(int)\n",
    "\n",
    "# prediction model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, neurons, dropout, constant_indices, constant_values, mask):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        #self.linear = nn.Linear(num_feat, num_item)\n",
    "        self.linear = nn.Sequential( \n",
    "            nn.Linear(input_size, neurons),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(neurons, neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(neurons, output_size)\n",
    "        )\n",
    "        self.constant_indices = constant_indices\n",
    "        self.constant_values = constant_values\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        for i in range(len(self.constant_indices)):\n",
    "            if self.constant_indices[i] == 1:\n",
    "                if i < 24:\n",
    "                    out[:,i] = self.constant_values[0]\n",
    "                else:\n",
    "                    out[:,i] = self.constant_values[1]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize for regret, which will have to be done on validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(config=None):#, num_epochs=20, lr=1e-2):\n",
    "    # set adam optimizer\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        #pprint(config)\n",
    "        reg = LinearRegression(num_feat, num_item, config.neurons, config.dropout, constant_indices=constant_indices, constant_values=[price_H, price_H], mask=grad_mask)\n",
    "        # cuda\n",
    "        if torch.cuda.is_available():\n",
    "            reg = reg.cuda()\n",
    "        # init SPO+ loss\n",
    "        spop = pyepo.func.SPOPlus\n",
    "    \n",
    "        optimizer = torch.optim.Adam(reg.parameters(), lr=config.lr)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = config.gamma)\n",
    "        # train mode\n",
    "        reg.train()\n",
    "        # init log\n",
    "        loss_log = []\n",
    "        # using validation regret instead of test regret\n",
    "        loss_log_regret = [regretParams(reg, hydrogenPlanning_2, loader_test, wind_test)]\n",
    "        # init elpased time\n",
    "        elapsed = 0\n",
    "        wandb.watch(reg, log_freq=100)\n",
    "        for epoch in range(config.num_epochs):\n",
    "            # start timing\n",
    "            tick = time.time()\n",
    "            # load data\n",
    "            for i, data in enumerate(tqdm(loader_train)):\n",
    "                wind = wind_train[i]\n",
    "                opt_model = hydrogenPlanning_2(wind)\n",
    "                loss_func = spop(opt_model, processes=1)\n",
    "                x, c, w, z = data\n",
    "                # cuda\n",
    "                if torch.cuda.is_available():\n",
    "                    x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "                # forward pass\n",
    "                cp = reg(x)\n",
    "                if config.method_name == \"spo+\":\n",
    "                    loss = loss_func(cp, c, w, z)\n",
    "                if config.method_name in [\"ptb\", \"pfy\", \"imle\", \"nce\", \"cmap\"]:\n",
    "                    loss = loss_func(cp, w)\n",
    "                if config.method_name in [\"dbb\", \"nid\"]:\n",
    "                    loss = loss_func(cp, c, z)\n",
    "                if config.method_name == \"ltr\":\n",
    "                    loss = loss_func(cp, c)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                #for param in reg.parameters():\n",
    "                #    if param.grad is not None:\n",
    "                #        param.grad = (param.grad.T * reg.mask).T.type(torch.FloatTensor)\n",
    "                #for name, param in reg.named_parameters():\n",
    "                #    wandb.log({f\"{name}.grad\": param.grad.norm()}, step=epoch)\n",
    "                optimizer.step()\n",
    "                # record time\n",
    "                tock = time.time()\n",
    "                elapsed += tock - tick\n",
    "                # log\n",
    "                loss_log.append(loss.item())\n",
    "                wandb.log({\"Linear loss\": loss})\n",
    "            lr_scheduler.step()\n",
    "            # validation regret\n",
    "            regret = regretParams(reg, hydrogenPlanning_2, loader_test, wind_test)\n",
    "            loss_log_regret.append(regret)\n",
    "            wandb.log({\"Regret\": regret})\n",
    "            print(\"Epoch {:2},  Loss: {:9.4f},  Regret: {:7.4f}%\".format(epoch+1, loss.item(), regret*100))\n",
    "      \n",
    "        print(\"Total Elapsed Time: {:.2f} Sec.\".format(elapsed))\n",
    "        return reg, loss_log, loss_log_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'Regret'},\n",
      " 'parameters': {'dropout': {'values': [0.1, 0.2, 0.3]},\n",
      "                'gamma': {'values': [0.9, 0.95, 0.99]},\n",
      "                'lr': {'values': [0.01, 0.001, 0.0001]},\n",
      "                'method_name': {'value': 'spo+'},\n",
      "                'neurons': {'values': [32, 64, 128]},\n",
      "                'num_epochs': {'values': [10, 20]}}}\n",
      "Create sweep with ID: h36gl3an\n",
      "Sweep URL: https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "import pprint\n",
    "sweep_config = {\n",
    "    'method': 'random', # grid, random\n",
    "    'metric': {\n",
    "      'name': 'Regret',\n",
    "      'goal': 'minimize'   \n",
    "    },\n",
    "}\n",
    "parameters_dict =  {\n",
    "        'lr': {\n",
    "            'values': [1e-2, 1e-3, 1e-4]\n",
    "        },\n",
    "        'gamma': {\n",
    "            'values': [0.9, 0.95, 0.99]\n",
    "        },\n",
    "        'num_epochs': {\n",
    "            'values': [10,20]\n",
    "        },\n",
    "        'neurons': {\n",
    "            'values': [32, 64, 128]\n",
    "            },\n",
    "            'dropout': {\n",
    "                'values': [0.1, 0.2, 0.3]\n",
    "            },\n",
    "            #\"loss_function\": {\"value\":spop},\n",
    "            \"method_name\": {\"value\":\"spo+\"},\n",
    "    }\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "pprint.pprint(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"Pyepo_special\",project=\"Sweep Pyepo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1a9gfa2m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmethod_name: spo+\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneurons: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Frede\\Documents\\DTU\\2024\\Special Course\\git\\main_folder\\models\\PyEpo\\wandb\\run-20240515_105723-1a9gfa2m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/1a9gfa2m' target=\"_blank\">whole-sweep-1</a></strong> to <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/1a9gfa2m' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/1a9gfa2m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 63.66it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 42.72it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 65.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1,  Loss: 27190.9375,  Regret: 52.0185%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.78it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 66.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2,  Loss: 28921.9395,  Regret: 51.9295%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.31it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 69.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3,  Loss: 23685.6738,  Regret: 51.9805%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.93it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 70.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4,  Loss: 25170.1016,  Regret: 52.0878%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.06it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 64.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5,  Loss: 20818.5762,  Regret: 51.9343%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.58it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 72.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6,  Loss: 19877.0352,  Regret: 53.4135%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.20it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 69.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7,  Loss: 17154.7520,  Regret: 54.4387%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.13it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 70.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8,  Loss: 16348.4785,  Regret: 57.6322%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.89it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 62.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9,  Loss: 18439.6035,  Regret: 58.0950%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 41.67it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 66.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10,  Loss: 17089.8594,  Regret: 54.7697%\n",
      "Total Elapsed Time: 305.45 Sec.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Linear loss</td><td>▄█▃▅▅▇▄▆▅▇▃▅█▆▂▅▅▃▄▄▅▆▂█▇▄▃▂▃▂▃▆▇▂▂▅▄▁▁▆</td></tr><tr><td>Regret</td><td>▁▁▁▁▁▃▄▇█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Linear loss</td><td>17089.85938</td></tr><tr><td>Regret</td><td>0.5477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-1</strong> at: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/1a9gfa2m' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/1a9gfa2m</a><br/> View project at: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_105723-1a9gfa2m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 30j6sade with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmethod_name: spo+\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneurons: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Frede\\Documents\\DTU\\2024\\Special Course\\git\\main_folder\\models\\PyEpo\\wandb\\run-20240515_105754-30j6sade</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade' target=\"_blank\">gallant-sweep-2</a></strong> to <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 56.46it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 41.38it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 56.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1,  Loss: 25205.6484,  Regret: 51.8141%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.69it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 62.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2,  Loss: 25052.7148,  Regret: 51.8944%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.50it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 60.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3,  Loss: 24915.0898,  Regret: 52.4848%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 37.63it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 55.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4,  Loss: 24098.4902,  Regret: 52.4390%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.74it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 44.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5,  Loss: 23116.4746,  Regret: 52.3288%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 35.84it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 58.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6,  Loss: 22483.4668,  Regret: 52.7293%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 43.49it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 63.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7,  Loss: 20950.5898,  Regret: 53.8931%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.42it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8,  Loss: 20067.0566,  Regret: 53.2829%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.39it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 47.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9,  Loss: 19390.4121,  Regret: 53.7761%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.22it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10,  Loss: 17979.7480,  Regret: 53.9431%\n",
      "Total Elapsed Time: 347.66 Sec.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Linear loss</td><td>▄█▆▆▄▇▃▆▅▆▃▄▆▆▃▅▅▂▄▄▃▅▂▇▆▁▃▃▂▂▂▇▇▁▂▄▁▁▂▆</td></tr><tr><td>Regret</td><td>▁▁▃▃▃▄█▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Linear loss</td><td>17979.74805</td></tr><tr><td>Regret</td><td>0.53943</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-sweep-2</strong> at: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade</a><br/> View project at: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_105754-30j6sade\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss_log, loss_log_regret = trainModel(loss_function=spop, method_name=\"spo+\")\n",
    "wandb.agent(sweep_id, function=trainModel,count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Frede\\Documents\\DTU\\2024\\Special Course\\git\\main_folder\\models\\PyEpo\\wandb\\run-20240515_105823-30j6sade</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade' target=\"_blank\">gallant-sweep-2</a></strong> to <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/sweeps/h36gl3an</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 63.44it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 38.84it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 62.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1,  Loss: 24898.6602,  Regret: 51.8141%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.93it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 63.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2,  Loss: 24210.2676,  Regret: 51.9260%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.78it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 47.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3,  Loss: 24098.8496,  Regret: 52.3019%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 37.96it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 60.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4,  Loss: 24231.0156,  Regret: 52.7000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 41.81it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 49.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5,  Loss: 22749.9824,  Regret: 52.1184%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.36it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 57.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6,  Loss: 21382.1602,  Regret: 52.7889%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.98it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 54.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7,  Loss: 19913.0078,  Regret: 52.8485%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.70it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 55.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8,  Loss: 20102.8145,  Regret: 53.0819%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 37.02it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9,  Loss: 18369.9102,  Regret: 53.0118%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.68it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 55.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10,  Loss: 18460.1660,  Regret: 53.3072%\n",
      "Total Elapsed Time: 332.68 Sec.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Linear loss</td><td>▄█▅▇▄▇▃▆▄▆▃▄▅▆▂▅▅▂▃▄▃▅▂▇█▁▃▃▂▂▃▆▇▁▃▅▂▁▂▆</td></tr><tr><td>Regret</td><td>▁▂▃▅▂▆▆▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Linear loss</td><td>18460.16602</td></tr><tr><td>Regret</td><td>0.53307</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-sweep-2</strong> at: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo/runs/30j6sade</a><br/> View project at: <a href='https://wandb.ai/Pyepo_special/Sweep%20Pyepo' target=\"_blank\">https://wandb.ai/Pyepo_special/Sweep%20Pyepo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_105823-30j6sade\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Redo training with best hyperparameters\n",
    "best_config={\n",
    "        'lr': 1e-2,\n",
    "        'gamma': 0.9,\n",
    "        'num_epochs': 10,\n",
    "        'neurons': 40,\n",
    "        'dropout': 0.5,\n",
    "        \"method_name\": \"spo+\",\n",
    "    }\n",
    "\n",
    "reg, loss_log, loss_log_regret = trainModel(best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_bids = []\n",
    "hydrogen_plan = []\n",
    "reg.eval()\n",
    "for i, data in enumerate(loader_test):\n",
    "    x, c, w, z = data\n",
    "    if torch.cuda.is_available():\n",
    "        x, c, w, z = x.cuda(), c.cuda(), w.cuda(), z.cuda()\n",
    "    predicted_costs = reg(x).detach().numpy()[0]\n",
    "    model = hydrogenPlanning_2(realized=wind_test[i])\n",
    "    model.setObjective(predicted_costs)\n",
    "    forward, hydrogen = model.get_plan()\n",
    "    forward_bids.extend(forward)\n",
    "    hydrogen_plan.extend(hydrogen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"forward bid\" : forward_bids,\"hydrogen production\" : hydrogen_plan}).to_csv(\"ILO_base.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyepo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
